{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing main libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leilasapple/anaconda/lib/python3.6/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/Users/leilasapple/.matplotlib/matplotlibrc\", line #621\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Path directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_data_path='/Users/leilasapple/Documents/Springboard/recruit-restaurant-visitor-forecasting/input_files/'\n",
    "output_data_path='/Users/leilasapple/Documents/Springboard/recruit-restaurant-visitor-forecasting/output_files/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data file which is generated by other part of project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv(os.path.join(output_data_path,'data1.csv'), encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(os.path.join(output_data_path,'data1.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the relevance of the features to the number of visitors: ckeck the regression coefficent \n",
    "5 first features are categorical. Therefore we ignore them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coff=[0.,0.,0.,0.]\n",
    "for i ,item in enumerate(data.keys()):\n",
    "    if i>4:\n",
    "        if np.corrcoef(data.iloc[:,i], data['visitor'])[0, 1]>0.2:\n",
    "            print(i,item,'\\t',np.corrcoef(data.iloc[:,i], data['visitor'])[0, 1])\n",
    "#        coff=np.concatenate(coff,np.corrcoef(data.iloc[:,i], data['visitor'])[0, 1])\n",
    "        \n",
    "#6 dt     0.265833704757\n",
    "#11 genre_area_index      0.247850154589\n",
    "#13 store_holiday_index   0.354912255956\n",
    "#15 store_month_index     0.477839293588\n",
    "#17 day_month_index       0.21999743032\n",
    "#18 holiday_day_month_index       0.230262207287\n",
    "#20 store_index   0.344677327477\n",
    "#21 store_day_index       0.44310819328\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extracting X and Y variable from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelinput=data.loc[:,[ 'genre', 'area', 'holiday', 'day','month','dt','store_index',\n",
    "                       'store_holiday_index','store_month_index',\n",
    "                       'store_day_index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=modelinput.values.copy()\n",
    "y=data.loc[:,'visitor'].values.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Encoding categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X = LabelEncoder()\n",
    "X[:,0] = labelencoder_X.fit_transform(X[:, 0])\n",
    "X[:,1] = labelencoder_X.fit_transform(X[:, 1])\n",
    "X[:,2] = labelencoder_X.fit_transform(X[:, 2])\n",
    "X[:,3] = labelencoder_X.fit_transform(X[:, 3])\n",
    "X[:,4] = labelencoder_X.fit_transform(X[:, 4])\n",
    "#X[:,5] = labelencoder_X.fit_transform(X[:, 5])\n",
    "#X[:,6] = labelencoder_X.fit_transform(X[:, 6])\n",
    "\n",
    "onehotencoder = OneHotEncoder(categorical_features = [0,1,2,3,4])\n",
    "X = onehotencoder.fit_transform(X).toarray().astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Categorizing independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_org=copy.deepcopy(y)\n",
    "\n",
    "for i ,item in enumerate(y):\n",
    "    if item <10: y[i]=1\n",
    "#    if item >=5 and item <10 :y[i]=2\n",
    "#    if item >=10 and item <15 :y[i]=3\n",
    "#    if item >=15 and item <20 :y[i]=4\n",
    "#    if item >=20 and item <30 :y[i]=5\n",
    "#    if item >=30 and item <40 :y[i]=6\n",
    "#    if item >=40 and item <50:y[i]=7\n",
    "#    if item >=50 and item <60 :y[i]=8\n",
    "#    if item >=60 and item <70 :y[i]=9\n",
    "    if item >=10: y[i]=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking for imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "balanced_ratio1=len(y[y==1])*100/len(y)\n",
    "balanced_ratio2=len(y[y==2])*100/len(y)\n",
    "\n",
    "print('Balanced ratios',balanced_ratio1,balanced_ratio2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Spliting the data to test and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)\n",
    "y_train=y_train.astype(int)\n",
    "y_test=y_test.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['bootstrap', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_split', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'n_estimators', 'n_jobs', 'oob_score', 'random_state', 'verbose', 'warm_start'])\n",
      "{'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_split': 1e-07, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 150, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
      "SCORE:  1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"print('feature:')\\nfor i in range(len(model.feature_importances_)):\\n    if model.feature_importances_[i]*1000>10 :\\n        print(i,model.feature_importances_[i]*1000)\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators = 50, random_state = 0,bootstrap=True,n_jobs=-1)\n",
    "#,min_samples_leaf=5,min_samples_split=5,max_depth=None)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print(model.get_params().keys())\n",
    "print(model.get_params())\n",
    "print('SCORE: ',model.score(x_train,y_train))\n",
    "\n",
    "'''print('feature:')\n",
    "for i in range(len(model.feature_importances_)):\n",
    "    if model.feature_importances_[i]*1000>10 :\n",
    "        print(i,model.feature_importances_[i]*1000)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Applying the model over test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_pred=np.around(y_pred).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluation the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(\"Precision: \",metrics.precision_score(y_test, y_pred,average='micro'))\n",
    "print(\"Recall: \",metrics.recall_score(y_test, y_pred,average='micro'))\n",
    "print('accuracy: ',metrics.accuracy_score(y_test, y_pred))\n",
    "f= open(os.path.join(output_data_path,'output_RFC.txt'),\"a\")\n",
    "f.write(str(datetime.now())+ '\\n')\n",
    "f.write(str(modelinput.keys())+ '\\n')\n",
    "f.write(\"Model : \"+str(model)+ '\\n')\n",
    "f.write(\"SCORE : \"+str(model.score(x_train,y_train)) + '\\n')\n",
    "f.write(\"Accuracy : \"+str(metrics.accuracy_score(y_test, y_pred)) + '\\n')\n",
    "f.write('Precision: '+str(metrics.precision_score(y_test, y_pred,average='micro'))+ '\\n')\n",
    "f.write('Recall: '+str(metrics.recall_score(y_test,y_pred,average='micro'))+ '\\n')\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion matrix evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "CONFM = confusion_matrix(y_test, y_pred)\n",
    "tn = CONFM[0,0]; fp = CONFM[0,1]; fn = CONFM[1,0]; tp = CONFM[1,1];\n",
    "\n",
    "NP = fn+tp # Num positive examples\n",
    "NN = tn+fp # Num negative examples\n",
    "N  = NP+NN\n",
    "CONFM_accuracy=(tp+tn)/N\n",
    "print('accuracy from confusion matrix',CONFM_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Choosing hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "datetime.now().time()\n",
    "param_grid = {#\"n_estimators\": [10,50,100],\n",
    "    \"max_depth\": [None,2,4,6],\n",
    "#    \"criterion\" : [\"gini\", \"entropy\"],\n",
    "#    \"max_features\": np.arange(5,55,250),\n",
    "    \"min_samples_split\": [2,4,6],\n",
    "    \"min_samples_leaf\": [1,2,4,6],\n",
    "    \"max_leaf_nodes\"=[None,2,3,4,5],\n",
    "    \"n_jobs\"=[-1,1]}\n",
    "gridsearch=GridSearchCV(model, param_grid, scoring='accuracy',cv=10)\n",
    "gridsearch=gridsearch.fit(x_train,y_train)\n",
    "\n",
    "datetime.now().time()\n",
    "print(gridsearch.best_params_)\n",
    "print(gridsearch.best_score_)\n",
    "\n",
    "f= open(os.path.join(output_data_path,'output_RFC.txt'),\"a\")\n",
    "f.write(str(datetime.now().time())+ '\\n')\n",
    "f.write(\"GridSearch : \"+str(gridsearch)+ '\\n')\n",
    "f.write(\"SCORE : \"+str(gridsearch.best_score_) + '\\n')\n",
    "\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visulazation the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig, ax=plt.figure(figsize=(20, 15))\n",
    "ax.scatter(y_test,marker='*',c='#FF6103',label='True values')\n",
    "ax.scatter(y_pred,marker='o',c='#9932CC',label='Predicted values')\n",
    "legend = ax.legend(loc='upper center')\n",
    "# The frame is matplotlib.patches.Rectangle instance surrounding the legend.\n",
    "frame = legend.get_frame()\n",
    "frame.set_facecolor('0.90')\n",
    "\n",
    "# Set the fontsize\n",
    "for label in legend.get_texts():\n",
    "    label.set_fontsize('large')\n",
    "\n",
    "for label in legend.get_lines():\n",
    "    label.set_linewidth(1.5)  # the legend line width\n",
    "plt.show()\n",
    "fig.savefig(os.path.join(output_data_path,'Forcast.png'))   # save the figure to file\\n\",\n",
    "plt.close(fig) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
